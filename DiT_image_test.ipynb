{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DiT Image Generation Test Notebook\n",
        "\n",
        "Use this notebook to quickly verify recent model changes (e.g., newly added residual connections) by sampling images from a DiT checkpoint.\n",
        "\n",
        "**Note:** This notebook works in both Google Colab and local Jupyter environments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository root: C:\\Users\\schoo\\Documents\\GitHub\\DiT\n",
            "Current working directory: /content\n",
            "Python path: ['C:\\\\Users\\\\schoo\\\\Documents\\\\GitHub\\\\DiT', '/content', '/env/python']\n",
            "\n",
            "⚠️  WARNING: models.py not found at C:\\Users\\schoo\\Documents\\GitHub\\DiT\n",
            "Please edit the repo_root variable in the cell above to point to your DiT directory\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'diffusion'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1778948867.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_diffusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoencoderKL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusion'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Detect environment and setup paths\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "print(f\"Running in: {'Google Colab' if in_colab else 'Local environment'}\")\n",
        "\n",
        "if in_colab:\n",
        "    # Clone the repo if in Colab\n",
        "    if not os.path.exists('/content/DiT'):\n",
        "        print(\"Cloning DiT repository...\")\n",
        "        import subprocess\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/facebookresearch/DiT.git'], cwd='/content')\n",
        "    \n",
        "    # Change to DiT directory\n",
        "    os.chdir('/content/DiT')\n",
        "    \n",
        "    # Install dependencies\n",
        "    print(\"Installing dependencies...\")\n",
        "    import subprocess\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'diffusers', 'timm'])\n",
        "    \n",
        "    repo_root = '/content/DiT'\n",
        "else:\n",
        "    # Local environment - assume we're in the DiT directory\n",
        "    repo_root = os.getcwd()\n",
        "    # If models.py is not in current dir, try parent\n",
        "    if not os.path.exists(os.path.join(repo_root, 'models.py')):\n",
        "        repo_root = os.path.dirname(repo_root)\n",
        "\n",
        "# Add to Python path\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "\n",
        "print(f\"Repository root: {repo_root}\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify the path is correct\n",
        "if os.path.exists(os.path.join(repo_root, 'models.py')):\n",
        "    print(\"✓ Repository root found successfully\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  WARNING: models.py not found at {repo_root}\")\n",
        "\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from diffusion import create_diffusion\n",
        "from diffusers.models import AutoencoderKL\n",
        "from download import find_model\n",
        "from models import DiT_models\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.set_grad_enabled(False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Configuration ---------------------------------------------------------\n",
        "model_key = \"DiT-XL/2\"      # Choose from models.DiT_models\n",
        "image_size = 256             # 256 or 512 for auto-downloaded checkpoints\n",
        "vae_variant = \"mse\"          # \"mse\" or \"ema\" (Stable Diffusion VAE variants)\n",
        "num_sampling_steps = 100     # More steps -> better quality, slower\n",
        "cfg_scale = 4.0\n",
        "class_labels = [207, 360, 387, 974, 88, 979, 417, 279]  # ImageNet class IDs\n",
        "samples_per_row = 4\n",
        "seed = 0\n",
        "custom_ckpt = None          # Optional path to a custom DiT checkpoint\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "latent_size = image_size // 8\n",
        "\n",
        "if custom_ckpt is None:\n",
        "    if model_key != \"DiT-XL/2\":\n",
        "        raise ValueError(\"Automatic checkpoints are only available for DiT-XL/2. Provide custom_ckpt instead.\")\n",
        "    ckpt_path = f\"DiT-XL-2-{image_size}x{image_size}.pt\"\n",
        "else:\n",
        "    ckpt_path = custom_ckpt\n",
        "\n",
        "print(f\"Loading {model_key} from {ckpt_path}\")\n",
        "model = DiT_models[model_key](input_size=latent_size).to(device)\n",
        "state_dict = find_model(ckpt_path)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "diffusion = create_diffusion(str(num_sampling_steps))\n",
        "vae = AutoencoderKL.from_pretrained(f\"stabilityai/sd-vae-ft-{vae_variant}\").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = len(class_labels)\n",
        "z = torch.randn(n, 4, latent_size, latent_size, device=device)\n",
        "y = torch.tensor(class_labels, device=device)\n",
        "\n",
        "# Classifier-free guidance setup:\n",
        "z = torch.cat([z, z], dim=0)\n",
        "y_null = torch.tensor([1000] * n, device=device)\n",
        "y = torch.cat([y, y_null], dim=0)\n",
        "model_kwargs = dict(y=y, cfg_scale=cfg_scale)\n",
        "\n",
        "samples = diffusion.p_sample_loop(\n",
        "    model.forward_with_cfg,\n",
        "    z.shape,\n",
        "    z,\n",
        "    clip_denoised=False,\n",
        "    model_kwargs=model_kwargs,\n",
        "    progress=True,\n",
        "    device=device,\n",
        ")\n",
        "samples, _ = samples.chunk(2, dim=0)\n",
        "samples = vae.decode(samples / 0.18215).sample\n",
        "\n",
        "output_path = \"dit_test_samples.png\"\n",
        "save_image(samples, output_path, nrow=samples_per_row, normalize=True, value_range=(-1, 1))\n",
        "print(f\"Saved grid to {output_path}\")\n",
        "display(Image.open(output_path))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
