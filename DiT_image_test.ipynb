{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DiT Image Generation Test Notebook\n",
        "\n",
        "Use this notebook to quickly verify recent model changes (e.g., newly added residual connections) by sampling images from a DiT checkpoint.\n",
        "\n",
        "**Important for Colab users:** This notebook clones the original DiT repo from GitHub. To test your local modifications:\n",
        "1. Upload your modified `models.py` to Colab after running Cell 1, OR\n",
        "2. Run this notebook locally with Jupyter instead\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# Detect environment and setup paths\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "print(f\"Running in: {'Google Colab' if in_colab else 'Local environment'}\")\n",
        "\n",
        "if in_colab:\n",
        "    # Update or clone the repo\n",
        "    import subprocess\n",
        "    \n",
        "    if os.path.exists('/content/DiT'):\n",
        "        print(\"DiT repository exists. Pulling latest changes...\")\n",
        "        os.chdir('/content/DiT')\n",
        "        result = subprocess.run(['git', 'pull'], cwd='/content/DiT', capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.returncode == 0:\n",
        "            print(\"✓ Successfully updated DiT repository\")\n",
        "        else:\n",
        "            print(f\"⚠️ Pull failed: {result.stderr}\")\n",
        "    else:\n",
        "        print(\"DiT repository not found. Cloning...\")\n",
        "        result = subprocess.run(['git', 'clone', 'https://github.com/mrmc-speco/DiT.git'], cwd='/content', capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.returncode == 0:\n",
        "            print(\"✓ Successfully cloned DiT repository\")\n",
        "        else:\n",
        "            print(f\"⚠️ Clone failed: {result.stderr}\")\n",
        "    \n",
        "    # Change to DiT directory\n",
        "    os.chdir('/content/DiT')\n",
        "    \n",
        "    # Install dependencies\n",
        "    print(\"Installing dependencies...\")\n",
        "    import subprocess\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'diffusers', 'timm'])\n",
        "    \n",
        "    repo_root = '/content/DiT'\n",
        "else:\n",
        "    # Local environment - assume we're in the DiT directory\n",
        "    repo_root = os.getcwd()\n",
        "    # If models.py is not in current dir, try parent\n",
        "    if not os.path.exists(os.path.join(repo_root, 'models.py')):\n",
        "        repo_root = os.path.dirname(repo_root)\n",
        "\n",
        "# Add to Python path\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "\n",
        "print(f\"Repository root: {repo_root}\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify the path is correct\n",
        "if os.path.exists(os.path.join(repo_root, 'models.py')):\n",
        "    print(\"✓ Repository root found successfully\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  WARNING: models.py not found at {repo_root}\")\n",
        "\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from diffusion import create_diffusion\n",
        "from diffusers.models import AutoencoderKL\n",
        "from download import find_model\n",
        "from models import DiT_models\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.set_grad_enabled(False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Upload Modified models.py (Colab only)\n",
        "\n",
        "If you're in Colab and want to test your local modifications, run this cell to upload your modified `models.py` file:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Patch models.py with skip connection (Colab only)\n",
        "# import sys\n",
        "\n",
        "# in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# if in_colab:\n",
        "#     print(\"Applying skip connection patch to models.py...\")\n",
        "    \n",
        "#     # Use sed-like approach to patch the file\n",
        "#     import subprocess\n",
        "    \n",
        "#     # Create a Python script to patch the file\n",
        "#     patch_script = '''\n",
        "# import re\n",
        "\n",
        "# with open('/content/DiT/models.py', 'r') as f:\n",
        "#     content = f.read()\n",
        "\n",
        "# # Check if already patched\n",
        "# if 'skip = x' in content and 'preserve pre-block representation' in content:\n",
        "#     print(\"✓ Skip connection already applied!\")\n",
        "# else:\n",
        "#     # Patch forward method\n",
        "#     pattern = r\"(def forward\\\\(self, x, t, y\\\\):.*?\\\\\\\"\\\\\\\"\\\\\\\"\\\\n)\"\n",
        "#     replacement = r'\\\\1        # Log forward pass\\\\n        print(f\"[DiT Forward] Batch: {x.shape}, Timesteps: [{t.min().item():.0f}-{t.max().item():.0f}]\")\\\\n        '\n",
        "#     content = re.sub(pattern, replacement, content, flags=re.DOTALL)\n",
        "    \n",
        "#     # Add skip connection\n",
        "#     pattern = r\"(c = t \\\\+ y.*?# \\\\(N, D\\\\)\\\\n)        (for block in self\\\\.blocks:)\"\n",
        "#     replacement = r\"\\\\1        skip = x  # preserve pre-block representation\\\\n        \\\\2\"\n",
        "#     content = re.sub(pattern, replacement, content)\n",
        "    \n",
        "#     pattern = r\"(for block in self\\\\.blocks:.*?x = block\\\\(x, c\\\\).*?\\\\n)        (x = self\\\\.final_layer)\"\n",
        "#     replacement = r\"\\\\1        x = x + skip  # skip connection\\\\n        print(f'[DiT Forward] ✓ Skip applied across {len(self.blocks)} blocks')\\\\n        \\\\2\"\n",
        "#     content = re.sub(pattern, replacement, content, flags=re.DOTALL)\n",
        "    \n",
        "#     with open('/content/DiT/models.py', 'w') as f:\n",
        "#         f.write(content)\n",
        "    \n",
        "#     print(\"✓ Patch applied!\")\n",
        "# '''\n",
        "    \n",
        "#     with open('/tmp/patch.py', 'w') as f:\n",
        "#         f.write(patch_script)\n",
        "    \n",
        "#     result = subprocess.run(['python', '/tmp/patch.py'], capture_output=True, text=True)\n",
        "#     print(result.stdout)\n",
        "    \n",
        "#     if result.returncode == 0:\n",
        "#         print(\"⚠️  Please restart runtime (Runtime > Restart runtime) and re-run all cells\")\n",
        "#     else:\n",
        "#         print(f\"Error: {result.stderr}\")\n",
        "# else:\n",
        "#     print(\"Not in Colab - skipping patch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Configuration ---------------------------------------------------------\n",
        "model_key = \"DiT-XL/2\"      # Choose from models.DiT_models\n",
        "image_size = 256             # 256 or 512 for auto-downloaded checkpoints\n",
        "vae_variant = \"ema\"          # \"mse\" or \"ema\" (Stable Diffusion VAE variants)\n",
        "num_sampling_steps = 256     # More steps -> better quality, slower\n",
        "cfg_scale = 4.0\n",
        "class_labels = [387]  # ImageNet class IDs\n",
        "samples_per_row = 4\n",
        "seed = 0\n",
        "custom_ckpt = None          # Optional path to a custom DiT checkpoint\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "latent_size = image_size // 8\n",
        "\n",
        "if custom_ckpt is None:\n",
        "    if model_key != \"DiT-XL/2\":\n",
        "        raise ValueError(\"Automatic checkpoints are only available for DiT-XL/2. Provide custom_ckpt instead.\")\n",
        "    ckpt_path = f\"DiT-XL-2-{image_size}x{image_size}.pt\"\n",
        "else:\n",
        "    ckpt_path = custom_ckpt\n",
        "\n",
        "print(f\"Loading {model_key} from {ckpt_path}\")\n",
        "model = DiT_models[model_key](input_size=latent_size).to(device)\n",
        "state_dict = find_model(ckpt_path)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "diffusion = create_diffusion(str(num_sampling_steps))\n",
        "vae = AutoencoderKL.from_pretrained(f\"stabilityai/sd-vae-ft-{vae_variant}\").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = len(class_labels)\n",
        "z = torch.randn(n, 4, latent_size, latent_size, device=device)\n",
        "y = torch.tensor(class_labels, device=device)\n",
        "\n",
        "# Classifier-free guidance setup:\n",
        "z = torch.cat([z, z], dim=0)\n",
        "y_null = torch.tensor([1000] * n, device=device)\n",
        "y = torch.cat([y, y_null], dim=0)\n",
        "model_kwargs = dict(y=y, cfg_scale=cfg_scale)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting sampling process...\")\n",
        "print(f\"Will run {num_sampling_steps} diffusion steps\")\n",
        "print(\"Watch for [DiT CFG] and [DiT Forward] log messages below:\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "samples = diffusion.p_sample_loop(\n",
        "    model.forward_with_cfg,\n",
        "    z.shape,\n",
        "    z,\n",
        "    clip_denoised=False,\n",
        "    model_kwargs=model_kwargs,\n",
        "    progress=False,  # Disable tqdm to see our prints clearly\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Sampling complete! Decoding with VAE...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "samples, _ = samples.chunk(2, dim=0)\n",
        "samples = vae.decode(samples / 0.18215).sample\n",
        "\n",
        "output_path = \"dit_test_samples.png\"\n",
        "save_image(samples, output_path, nrow=samples_per_row, normalize=True, value_range=(-1, 1))\n",
        "print(f\"✓ Saved grid to {output_path}\")\n",
        "display(Image.open(output_path))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
